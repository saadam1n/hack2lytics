{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.63.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting instructor\n",
      "  Downloading instructor-1.7.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/albert818/Documents/hackathon_deep/hack2lytics/.venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from instructor)\n",
      "  Downloading aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.4 (from instructor)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor)\n",
      "  Downloading pydantic_core-2.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting requests<3.0.0,>=2.32.3 (from instructor)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich<14.0.0,>=13.7.0 (from instructor)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<10.0.0,>=9.0.0 (from instructor)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typer<1.0.0,>=0.9.0 (from instructor)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/albert818/Documents/hackathon_deep/hack2lytics/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.4->instructor)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor)\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.32.3->instructor)\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.32.3->instructor)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.7.0->instructor)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/albert818/Documents/hackathon_deep/hack2lytics/.venv/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor) (2.19.1)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.9.0->instructor)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.9.0->instructor)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "Downloading instructor-1.7.2-py3-none-any.whl (71 kB)\n",
      "Downloading aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: urllib3, tqdm, tenacity, sniffio, shellingham, pydantic-core, propcache, multidict, mdurl, MarkupSafe, jiter, idna, h11, frozenlist, docstring-parser, distro, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, requests, pydantic, markdown-it-py, jinja2, httpcore, anyio, aiosignal, rich, httpx, aiohttp, typer, openai, instructor\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "generate-parameter-library-py 0.3.8 requires pyyaml, which is not installed.\n",
      "generate-parameter-library-py 0.3.8 requires typeguard, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 async-timeout-5.0.1 attrs-25.1.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 distro-1.9.0 docstring-parser-0.16 frozenlist-1.5.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 instructor-1.7.2 jinja2-3.1.5 jiter-0.8.2 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.1.0 openai-1.63.2 propcache-0.3.0 pydantic-2.10.6 pydantic-core-2.27.2 requests-2.32.3 rich-13.9.4 shellingham-1.5.4 sniffio-1.3.1 tenacity-9.0.0 tqdm-4.67.1 typer-0.15.1 urllib3-2.3.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import builtins\n",
    "\n",
    "def wprint(*args, width=70, **kwargs):\n",
    "    \"\"\"\n",
    "    Custom print function that wraps text to a specified width.\n",
    "\n",
    "    Args:\n",
    "    *args: Variable length argument list.\n",
    "    width (int): The maximum width of wrapped lines.\n",
    "    **kwargs: Arbitrary keyword arguments.\n",
    "    \"\"\"\n",
    "    wrapper = textwrap.TextWrapper(width=width)\n",
    "\n",
    "    # Process all arguments to make sure they are strings and wrap them\n",
    "    wrapped_args = [wrapper.fill(str(arg)) for arg in args]\n",
    "\n",
    "    # Call the built-in print function with the wrapped text\n",
    "    builtins.print(*wrapped_args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import instructor\n",
    "from getpass import getpass\n",
    "from openai import Client\n",
    "client = Client(api_key = \"XXXX\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_completion(message, agent, funcs, thread):\n",
    "    \"\"\"\n",
    "    Executes a thread based on a provided message and retrieves the completion result.\n",
    "\n",
    "    This function submits a message to a specified thread, triggering the execution of an array of functions\n",
    "    defined within a func parameter. Each function in the array must implement a `run()` method that returns the outputs.\n",
    "\n",
    "    Parameters:\n",
    "    - message (str): The input message to be processed.\n",
    "    - agent (OpenAI Assistant): The agent instance that will process the message.\n",
    "    - funcs (list): A list of function objects, defined with the instructor library.\n",
    "    - thread (Thread): The OpenAI Assistants API thread responsible for managing the execution flow.\n",
    "\n",
    "    Returns:\n",
    "    - str: The completion output as a string, obtained from the agent following the execution of input message and functions.\n",
    "    \"\"\"\n",
    "\n",
    "    # create new message in the thread\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=message\n",
    "    )\n",
    "\n",
    "    # run this thread\n",
    "    run = client.beta.threads.runs.create(\n",
    "      thread_id=thread.id,\n",
    "      assistant_id=agent.id,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "      # wait until run completes\n",
    "      while run.status in ['queued', 'in_progress']:\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "          thread_id=thread.id,\n",
    "          run_id=run.id\n",
    "        )\n",
    "        time.sleep(1)\n",
    "\n",
    "      # function execution\n",
    "      if run.status == \"requires_action\":\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "          wprint('\\033[31m' + str(tool_call.function), '\\033[0m')\n",
    "          # find the tool to be executed\n",
    "          func = next(iter([func for func in funcs if func.__name__ == tool_call.function.name]))\n",
    "\n",
    "          try:\n",
    "            # init tool\n",
    "            func = func(**eval(tool_call.function.arguments))\n",
    "            # get outputs from the tool\n",
    "            output = func.run()\n",
    "          except Exception as e:\n",
    "            output = \"Error: \" + str(e)\n",
    "\n",
    "          wprint(f\"\\033[33m{tool_call.function.name}: \", output, '\\033[0m')\n",
    "          tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": output})\n",
    "\n",
    "        # submit tool outputs\n",
    "        run = client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_outputs\n",
    "        )\n",
    "      # error\n",
    "      elif run.status == \"failed\":\n",
    "        raise Exception(\"Run Failed. Error: \", run.last_error)\n",
    "      # return assistant message\n",
    "      else:\n",
    "        messages = client.beta.threads.messages.list(\n",
    "          thread_id=thread.id\n",
    "        )\n",
    "        message = messages.data[0].content[0].text.value\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "code_assistant_funcs = []\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name='Code Assistant Agent',\n",
    "  instructions=\"As a top-tier web developement Cybersecurity AI, you are adept at analyzing potential vulnerabilities in API calls. You will analyze the Website Source Code file attached for exposure of sensitive data, security vulnerabilities, and compliance with best practices (e.g., OWASP, GDPR). Find all possible vulnerabilities and exploits while prioritize glaring issues. \",\n",
    "  model=\"gpt-4o-mini\",\n",
    "  tools=[{\"type\": \"file_search\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(name=\"Website Source File\")\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"/home/albert818/Documents/hackathon_deep/hack2lytics/AdminPage.ts\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_67ba13bfeda08191a45fd7e6f8d00108'])\n"
     ]
    }
   ],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"/home/albert818/Documents/hackathon_deep/hack2lytics/AdminPage.ts\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Are there any cybersecurity issues with this typescript source code for my\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > Please upload the TypeScript source code file so I can help you analyze it for potential cybersecurity issues.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as PI Man. The user has a premium account.\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a cybersecurity expert specializing in web development and security. Analyze the following request for exposure of sensitive data, security vulnerabilities, and compliance with best practices (e.g., OWASP, GDPR). Provide recommendations for improving security.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "         REQUEST\n",
    "{\"query\":\"query ListEvents($filter: ModelEventFilterInput, $limit: Int, $nextToken: String) {\\n  listEvents(filter: $filter, limit: $limit, nextToken: $nextToken) {\\n    items {\\n      id\\n      name\\n      description\\n      status\\n      requireRSVP\\n      canRSVP\\n      start\\n      end\\n      location\\n      points\\n      checkInCode\\n      createdAt\\n      updatedAt\\n      _version\\n      _deleted\\n      _lastChangedAt\\n      __typename\\n    }\\n    nextToken\\n    startedAt\\n    __typename\\n  }\\n}\\n\",\"variables\":{\"filter\":{\"_deleted\":{\"ne\":true}},\"limit\":1000}}\n",
    "\n",
    "RESPONSE\n",
    "{\"data\":{\"listEvents\":{\"items\":[{\"id\":\"09d73bcd-6ef0-4a17-ad86-c4f100384ae2\",\"name\":\"Sunday Breakfast\",\"description\":\"Blue Donkey Coffee and Bagels\",\"status\":false,\"requireRSVP\":false,\"canRSVP\":false,\"start\":\"2025-02-23T14:30:00.000Z\",\"end\":\"2025-02-23T15:30:00.000Z\",\"location\":\"Klaus 1116W\",\"points\":0,\"checkInCode\":\"Bagul\",\"createdAt\":\"2025-02-20T20:36:35.504Z\",\"updatedAt\":\"2025-02-21T04:06:32.338Z\",\"_version\":2,\"_deleted\":null,\"_lastChangedAt\":1740110792378,\"__typename\":\"Event\"},{\"id\":\"a583ccdb-16d6-47dc-b4dd-51c8f12dd3ae\",\"name\":\"Saturday Lunch\",\"description\":\"Moes Burritos\\n** ALL ITEMS CONTAIN GLUTEN**\",\"status\":false,\"requireRSVP\":false,\"canRSVP\":false,\"start\":\"2025-02-22T18:00:00.000Z\",\"end\":\"2025-02-22T19:00:00.000Z\",\"location\":\"Klaus 1116W\",\"points\":0,\"checkInCode\":\"lonch\",\"createdAt\":\"2025-02-20T20:19:47.857Z\",\"updatedAt\":\"2025-02-21T04:04:28.124Z\",\"_version\":4,\"_deleted\":null,\"_lastChangedAt\":1740110668170,\"__typename\":\"Event\"},{\"id\":\"f6f5d6bb-9c35-4f58-9e51-67c3033b2ae2\",\"name\":\"Sponsor Fair\",\"description\":\"ChitChat!\",\"status\":false,\"requireRSVP\":false,\"canRSVP\":false,\"start\":\"2025-02-22T00:15:00.000Z\",\"end\":\"2025-02-22T01:15:00.000Z\",\"location\":\"Klaus Atrium\",\"points\":0,\"checkInCode\":\"vibes\",\"createdAt\":\"2025-02-20T02:25:49.629Z\",\"updatedAt\":\"2025-02-20T02:29:20.894Z\",\"_version\":3,\"_deleted\":null,\"_lastChangedAt\":1740018560942,\"__typename\":\"Event\"}\n",
    "    \"\"\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
